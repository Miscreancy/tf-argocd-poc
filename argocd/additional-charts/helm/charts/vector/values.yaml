# Default values for Vector
# See Vector helm documentation to learn more:
# https://vector.dev/docs/setup/installation/package-managers/helm/

# nameOverride -- Override the name of resources.
nameOverride: ""

# fullnameOverride -- Override the full name of resources.
fullnameOverride: vector

# role -- [Role](https://vector.dev/docs/setup/deployment/roles/) for this Vector instance, valid options are:
# "Agent", "Aggregator", and "Stateless-Aggregator".

# Each role is created with the following workloads:
# Agent = DaemonSet
# Aggregator = StatefulSet
# Stateless-Aggregator = Deployment
role: "Aggregator"

# rollWorkload -- Add a checksum of the generated ConfigMap to workload annotations.
rollWorkload: true

# commonLabels -- Add additional labels to all created resources.
commonLabels: {}

# Define the Vector image to use.
image:
  # image.repository -- Override default registry and name for Vector's image.
  repository: registry.cloud-tools.datastax.com/cloud-services-platform/vector
  # image.pullPolicy -- The [pullPolicy](https://kubernetes.io/docs/concepts/containers/images/#image-pull-policy) for
  # Vector's image.
  pullPolicy: IfNotPresent
  # image.pullSecrets -- The [imagePullSecrets](https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod)
  # to reference for the Vector Pods.
  pullSecrets: []
  # image.tag -- The tag to use for Vector's image.
  # @default -- Derived from the Chart's appVersion.
  tag: "0.25.1-alpine"
  # image.sha -- The SHA to use for Vector's image.
  sha: ""

# replicas -- Specify the number of Pods to create. Valid for the "Aggregator" and "Stateless-Aggregator" roles.
replicas: 2

# podManagementPolicy -- Specify the [podManagementPolicy](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#pod-management-policies)
# for the StatefulSet. Valid for the "Aggregator" role.
podManagementPolicy: OrderedReady

# Create a Secret resource for Vector to use.
secrets:
  # secrets.generic -- Each Key/Value will be added to the Secret's data key, each value should be raw and NOT base64
  # encoded. Any secrets can be provided here. It's commonly used for credentials and other access related values.
  # **NOTE: Don't commit unencrypted secrets to git!**
  generic: {}
    # my_variable: "my-secret-value"
    # datadog_api_key: "api-key"
    # awsAccessKeyId: "access-key"
    # awsSecretAccessKey: "secret-access-key"

autoscaling:
  # autoscaling.enabled -- Create a [HorizontalPodAutoscaler](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)
  # for Vector. Valid for the "Aggregator" and "Stateless-Aggregator" roles.
  enabled: false
  # autoscaling.minReplicas -- Minimum replicas for Vector's HPA.
  minReplicas: 1
  # autoscaling.maxReplicas -- Maximum replicas for Vector's HPA.
  maxReplicas: 10
  # autoscaling.targetCPUUtilizationPercentage -- Target CPU utilization for Vector's HPA.
  targetCPUUtilizationPercentage: 80
  # autoscaling.targetMemoryUtilizationPercentage -- (int) Target memory utilization for Vector's HPA.
  targetMemoryUtilizationPercentage:
  # autoscaling.customMetric -- Target a custom metric for autoscaling.
  customMetric: {}
    #  - type: Pods
    #    pods:
    #      metric:
    #        name: utilization
    #      target:
    #        type: AverageValue
    #        averageValue: 95
  # autoscaling.behavior -- Configure separate scale-up and scale-down behaviors.
  behavior: {}
    # scaleDown:
    #   stabilizationWindowSeconds: 300

podDisruptionBudget:
  # podDisruptionBudget.enabled -- Enable a [PodDisruptionBudget](https://kubernetes.io/docs/tasks/run-application/configure-pdb/)
  # for Vector.
  enabled: false
  # podDisruptionBudget.minAvailable -- The number of Pods that must still be available after an eviction.
  minAvailable: 1
  # podDisruptionBudget.maxUnavailable -- (int) The number of Pods that can be unavailable after an eviction.
  maxUnavailable:

rbac:
  # rbac.create -- If true, create and use RBAC resources. Only valid for the "Agent" role.
  create: false

psp:
  # psp.create -- If true, create a [PodSecurityPolicy](https://kubernetes.io/docs/concepts/security/pod-security-policy/)
  # resource. PodSecurityPolicy is deprecated as of Kubernetes v1.21, and will be removed in v1.25. Intended for use
  # with the "Agent" role.
  create: false

serviceAccount:
  # serviceAccount.create -- If true, create a ServiceAccount for Vector.
  create: true
  # serviceAccount.annotations -- Annotations to add to Vector's ServiceAccount.
  annotations: {}
  # serviceAccount.name -- The name of the ServiceAccount to use. If not set and serviceAccount.create is true, a name
  # is generated using the fullname template.
  name:
  # serviceAccount.automountToken -- Automount API credentials for Vector's ServiceAccount.
  automountToken: true

# podAnnotations -- Set annotations on Vector Pods.
podAnnotations: {}

# podLabels -- Set labels on Vector Pods.
podLabels:
  vector.dev/exclude: "true"

# podPriorityClassName -- Set the [priorityClassName](https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/#priorityclass)
# on Vector Pods.
podPriorityClassName: ""

# podHostNetwork -- Configure hostNetwork on Vector Pods.
podHostNetwork: false

# podSecurityContext -- Allows you to overwrite the default [PodSecurityContext](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/)
# for Vector Pods.
podSecurityContext: {}

# securityContext -- Specify securityContext on Vector containers.
securityContext: {}

# command -- Override Vector's default command.
command: []

# args -- Override Vector's default arguments.
args:
  - --config-dir
  - "/etc/vector/"

# env -- Set environment variables for Vector containers.
env: []

# envFrom -- Define environment variables from Secrets or ConfigMaps.
envFrom: []
#  - secretRef:
  #     name: vector

# containerPorts -- Manually define Vector's containerPorts, overriding automated generation of containerPorts.
containerPorts: []

# resources -- Set Vector resource requests and limits.
resources: {}
  # requests:
  #   cpu: 200m
  #   memory: 256Mi
  # limits:
  #   cpu: 200m
  #   memory: 256Mi

# lifecycle -- Set lifecycle hooks for Vector containers.
lifecycle: {}
  # preStop:
  #   exec:
  #     command:
  #     - /bin/sleep
  #     - "10"

# updateStrategy -- Customize the updateStrategy used to replace Vector Pods, this is also used for the
# DeploymentStrategy for the "Stateless-Aggregators". Valid options depend on the chosen role.

# Agent (DaemonSetUpdateStrategy): https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/daemon-set-v1/#DaemonSetSpec)
# Aggregator (StatefulSetUpdateStrategy): https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/stateful-set-v1/#StatefulSetSpec
# Stateless-Aggregator (DeploymentStrategy): https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/deployment-v1/
updateStrategy: {}
#   type: RollingUpdate
#   rollingUpdate:
#     maxUnavailable: 1

# terminationGracePeriodSeconds -- Override Vector's terminationGracePeriodSeconds.
terminationGracePeriodSeconds: 60

# nodeSelector -- Configure a [nodeSelector](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector)
# for Vector Pods.
nodeSelector: {}

# tolerations -- Configure Vector Pods to be scheduled on [tainted](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/)
# nodes.
tolerations: []

# affinity -- Configure [affinity](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity)
# rules for Vector Pods.
affinity: {}

# topologySpreadConstraints -- Configure [topology spread constraints](https://kubernetes.io/docs/concepts/scheduling-eviction/topology-spread-constraints/)
# for Vector Pods. Valid for the "Aggregator" and "Stateless-Aggregator" roles.
topologySpreadConstraints: []

# Configuration for Vector's Service.
service:
  # service.enabled -- If true, create and provide a Service resource for Vector.
  enabled: true
  # service.type -- Set the type for Vector's Service.
  type: "ClusterIP"
  # service.annotations -- Set annotations on Vector's Service.
  annotations: {}
  # service.topologyKeys -- Specify the [topologyKeys](https://kubernetes.io/docs/concepts/services-networking/service-topology/#using-service-topology)
  # field on Vector's Service.
  topologyKeys: []
  #   - "kubernetes.io/hostname"
  #   - "topology.kubernetes.io/zone"
  #   - "topology.kubernetes.io/region"
  #   - "*"
  # service.ports -- Manually set the Service ports, overriding automated generation of Service ports.
  ports:
    - name: fluent-forward
      port: 24224
      protocol: TCP
      targetPort: 24224
    - name: vector-api
      port: 8686
      protocol: TCP
      targetPort: 8686
  # service.externalTrafficPolicy -- Specify the [externalTrafficPolicy](https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip).
  externalTrafficPolicy: ""
  # service.loadBalancerIP -- Specify the [loadBalancerIP](https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer).
  loadBalancerIP: ""
  # service.ipFamilyPolicy -- Configure [IPv4/IPv6 dual-stack](https://kubernetes.io/docs/concepts/services-networking/dual-stack/).
  ipFamilyPolicy: ""
  # service.ipFamilies -- Configure [IPv4/IPv6 dual-stack](https://kubernetes.io/docs/concepts/services-networking/dual-stack/).
  ipFamilies: []

# Configuration for Vector's Headless Service.
serviceHeadless:
  # serviceHeadless.enabled -- If true, create and provide a Headless Service resource for Vector.
  enabled: true

# Configuration for Vector's Ingress.
ingress:
  # ingress.enabled -- If true, create and use an Ingress resource.
  enabled: false
  # ingress.className -- Specify the [ingressClassName](https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress),
  # requires Kubernetes >= 1.18
  className: ""
  # ingress.annotations -- Set annotations on the Ingress.
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  # ingress.hosts -- Configure the hosts and paths for the Ingress.
  hosts: []
  #  - host: chart-example.local
  #    paths:
  #      - path: /
  #        pathType: ImplementationSpecific
  #        # Specify the port name or number on the Service
  #        # Using name requires Kubernetes >=1.19
  #        port:
  #          name: ""
  #          number: ""
  # ingress.tls -- Configure TLS for the Ingress.
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

# existingConfigMaps -- List of existing ConfigMaps for Vector's configuration instead of creating a new one. Requires
# dataDir to be set. Additionally, containerPorts, service.ports, and serviceHeadless.ports should be specified based on
# your supplied configuration. If set, this parameter takes precedence over customConfig and the chart's default configs.
existingConfigMaps: []

# dataDir -- Specify the path for Vector's data, only used when existingConfigMaps are used.
dataDir: ""

# customConfig -- Override Vector's default configs, if used **all** options need to be specified. This section supports
# using helm templates to populate dynamic values. See Vector's [configuration documentation](https://vector.dev/docs/reference/configuration/)
# for all options.
customConfig:
  api:
    address: 127.0.0.1:8686
    enabled: true
    playground: false
  data_dir: /var/lib/vector

  sources:
    internal_metrics_source:
      type: internal_metrics
      scrape_interval_secs: 15
    fluent_in:
      type: fluent
      address: 0.0.0.0:24224

  sinks:
    splunk_logs_out:
      type: splunk_hec_logs
      inputs:
        - cleanup_fields
        - route_fluent._unmatched
      endpoint: |-
        {{ print "${SPLUNK_HEC_ENDPOINT}" }}
      default_token: |-
        {{ print "${SPLUNK_HEC_TOKEN}" }}
      index: |-
        {{ print "${SPLUNK_HEC_INDEX}" }}
      host_key: host
      source: |-
        {{ print "{{ _log_source }}" }}
      sourcetype: |-
        {{ print "{{ _log_sourcetype }}" }}
      encoding:
        codec: json
        timestamp_format: unix
        except_fields:
          - "_log_sourcetype"
          - "_log_source"

  transforms:
    internal_metrics_tag:
      type: remap
      inputs:
        - internal_metrics_source
      source: |-
        .tags.environment = "{{ .Values.shortEnv }}"
        .tags.cluster = "{{ .Values.clusterID }}"
        .tags.app = "platform-observability"
        # peer_addr has the format ip:port. Port numbers cause a tag cardinality explosion, 
        # but we don't care about the port anyway so just drop it and keep the ip.
        if is_string(.tags.peer_addr) {
          addr = split(.tags.peer_addr, ":") ?? []
          .tags.peer_addr = addr[0]
        }

    internal_metrics_cardinality_limit:
      type: tag_cardinality_limit
      inputs:
        - internal_metrics_tag
      mode: probabilistic
      fields:
        value_limit: 500
        limit_exceeded_action: drop_tag

    normalize_fluent:
      type: remap
      inputs:
        - fluent_in
      source: |-
        ._log_sourcetype = "UNKNOWN"
        ._log_source = "UNKNOWN"
        .fluent_tag = del(.tag)
        if starts_with(.fluent_tag, "host.") ?? false {
          ._log_sourcetype = "syslog"
          ._log_source = .SYSLOG_IDENTIFIER
        } else if starts_with(.fluent_tag, "kube.") ?? false {
          ._log_sourcetype = "container"
          if .kubernetes.container_name != null {
            ._log_source = .kubernetes.container_name
          }
          if .kubernetes.host != null {
            .host = .kubernetes.host
          }
          .fluent_ts = del(.timestamp)
          .container_ts = to_timestamp(del(.time)) ?? .fluent_ts
          ."k8s-container_name" = .kubernetes.container_name
          ."k8s-container_image" = .kubernetes.container_image
          ."k8s-host" = .kubernetes.host
          ."k8s-labels-pod-template-hash" = .kubernetes.labels."pod-template-hash"
          ."k8s-namespace_name" = .kubernetes.namespace_name
          ."k8s-pod_name" = .kubernetes.pod_name
          ."k8s-app" = .kubernetes.labels.app
          ."k8s-component" = .kubernetes.labels.component
          del(.p)
          if exists(.log) {               # docker format
            .raw_message = del(.log)
          } else if exists(.message) {    # cri format
            .raw_message = del(.message)
          }
        }

    # handle different sourcetypes
    route_fluent:
      type: route
      inputs:
        - normalize_fluent
      route:
        container: ._log_sourcetype == "container"

    # parse known container formats
    parse_container:
      type: remap
      inputs:
        - route_fluent.container
      source: |-
        .raw_message = strip_whitespace(.raw_message) ?? .raw_message
        # this reg-ex parses multi-line log4j messages as found in DSE or CNDB including stack traces, extracts line source files and line numbers
        cndb, cndb_err = parse_regex(.raw_message, r'(?s)\A(?P<level>[A-Z]+) *\[(?P<thread_type>[^-.:#(\]]+)[-.:#]?(?P<thread_id>[^\]]*)\] (?P<timestamp>.{10} .{12}) *(?P<source_file>[^:]+):(?P<source_line>\d+) - *(?P<message>.*)')
        streaming, streaming_err = parse_regex(.raw_message, r'(?s)\A(?P<timestamp>\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2},\d{3}\+\d{4})\s+\[(?P<thread>[^]]+)\]\s+(?P<level>[A-Z]+)\s+(?P<source_file>[^ ]+)\s+-\s+(?P<message>.*)')
        if cndb_err == null {
          # cndb cndb format
          .format = "log4j"
          . |= cndb
          .source_line = to_int(.source_line) ?? .source_line
          .thread_id = to_int(.thread_id) ?? .thread_id
          .timestamp = replace(.timestamp, ",", ".") ?? .timestamp
          .timestamp = replace(.timestamp, " ", "T") ?? .timestamp
          .timestamp = .timestamp + "Z"
        } else if streaming_err == null {
          .format = "log4j"
          . |= streaming
        } else if .kubernetes.container_name == "apiserver" {
          .raw_message = strip_ansi_escape_codes(.raw_message) ?? .raw_message
          parsed, err = parse_regex(.raw_message, r'(?s)\A\[(?P<code>[^\]]*)\] (?P<timestamp>[^\[]*)\[(?P<level>[^\]]*)\] (?P<message>.*)')
          if err == null {
            # Oct 20 18:08:45.008
            .timestamp = parse_timestamp(parsed.timestamp, format: "%B %d %H:%M:%S.%f ") ?? null
            code = split(parsed.code, "::") ?? parsed.code
            .function = replace(code[1], "github.com/riptano/cndb/kubernetes/apiserver/", "") ?? code[1]
            code = split(code[0], ":") ?? code[0]
            .source_file = code[0]
            .source_line = code[1]
            if parsed.level == "D" {
              .level = "debug"
            } else if parsed.level == "I" {
              .level = "info"
            } else if parsed.level == "W" {
              .level = "warning"
            } else if parsed.level == "E" {
              .level = "error"
            } else {
              .level = parsed.level
            }
            fields = split(parsed.message, "] [") ?? []
            for_each(fields) -> |i, field| {
              kv = split(field, ":", limit: 2)
              key = kv[0]
              value = kv[1]
              if starts_with(key, "[") ?? false {
                key = slice(key, 1) ?? key
              }
              if contains(value, "] ") ?? false {
                kv = split(value, "] ", limit: 2) ?? [value]
                value = kv[0]
                .message = kv[1]
              }
              . = set!(., [key], value)
            }
          }
        # avoid incorrectly parsing messages that aren't really logfmt
        } else if (contains(.raw_message, "time=") || contains(.raw_message, "ts=")) && 
                  contains(.raw_message, "msg=") && 
                  contains(.raw_message, "level=") ?? false {
          . |= parse_logfmt(.raw_message) ?? {}
        } else {
          # try other formats
          parsed =
            parse_regex(.raw_message, r'(?s)(?P<timestamp>[\d-]+T[\d:.]+Z)\s+(?P<level>[A-Z]+)\s+(?P<source_file>[\w.]+)\s+(?P<message>.*)') ??
            parse_nginx_log(.raw_message, "combined") ??
            parse_nginx_log(.raw_message, "error") ??
            parse_klog(.raw_message) ??
            parse_json(.raw_message) ??
            {}
          ., ignored = merge(., parsed)
          # extract message and json from manager logs
          if .kubernetes.container_name == "manager" {
            parsed, err = parse_regex(.message, r'(?P<message>[^\t]+)\t*(?P<json>.*)')
            if err == null {
              .message = strip_whitespace(parsed.message) ?? parsed.message
              parsed.json = strip_whitespace(parsed.json) ?? parsed.json
              if length(parsed.json) > 0 ?? false {
                .operator, err = parse_json(parsed.json)
                if err != null {
                  log(err + " " + parsed.json, level: "error")
                }
              }
            }
          }
        }

    # handle different messages for container logs
    route_container:
      type: route
      inputs:
        - parse_container
      route:
        exception: |-
          .format == "log4j" && (contains(.message, "Exception") || contains(.message, "Error")) ?? false

    # make a SHA1 hash of exception + stack trace
    fingerprint_exception:
      type: remap
      inputs:
        - route_container.exception
      source: |-
        lines = split(.message, "\n") ?? []
        ex = []
        ex_noline = []
        found_stack = false
        for_each(lines) -> |i, line| {
          line = strip_whitespace(string(line))
          if match(line, r'[A-Za-z0-9_$](Exception|Error|Throwable)(:.*)$') {
            parsed = parse_regex!(line, r'^(?P<exception>(Caused by: )?[^:]+).*')
            ex = push(ex, parsed.exception)
            ex_noline = push(ex_noline, parsed.exception)
          } else if starts_with(line, "at ") {
            found_stack = true
            ex = push(ex, line)
            stripped = replace(line, r':\d+\)', ")")
            ex_noline = push(ex_noline, stripped)
          } else if ends_with(line, "frames omitted") {
            ex = push(ex, line)
            ex_noline = push(ex_noline, line)
          }
        }
        if found_stack {
          ex = join(ex, "\n") ?? ""
          ex_noline = join(ex_noline, "\n") ?? ""
          .fingerprint = sha1(ex)
          .fingerprint_noline = sha1(ex_noline)
          .event_type = "exception"
        }

    # rename fields for consistency
    normalize_fields:
      type: remap
      inputs:
        - fingerprint_exception
        - route_container._unmatched
      source: |-
        if is_string(.level) {
          .level = downcase(.level) ?? .level
          if .level == "warn" {
            .level = "warning"
          }
        }
        if exists(.file) && !exists(.source_file) {
          .source_file = del(.file)
        }
        if exists(.line) && !exists(.source_line) {
          .source_line = del(.line)
        }
        if exists(.ts) && !exists(.timestamp) {
          .timestamp = del(.ts)
        }
        if exists(.time) && !exists(.timestamp) {
          .timestamp = del(.time)
        }
        if !exists(.timestamp) {
          .timestamp = .container_ts
        }
        if is_string(.timestamp) {
          .timestamp = to_timestamp(.timestamp) ?? .timestamp
        }
        if exists(.msg) && !exists(.message) {
          .message = del(.msg)
        }
        if exists(.raw_message) && !exists(.message) {
          .message = .raw_message
        }

    # Prevent a single container/message from spamming the logs
    throttle_key:
      type: remap
      inputs:
        - normalize_fields
      source: |-
        {{- if .Values.throttleEnabled }}
        # set default key for most container types
        key = {}
        key.cluster = .cluster
        key.sourcetype = ._log_sourcetype
        key.source = ._log_source
        key.source_file = .source_file
        key.source_line = .source_line
        key.fingerprint = .fingerprint
        # set cap according to message size
        len = length(.raw_message) ?? 0
        if len < 500 {
          .throttle_cap = "high"
        } else if len < 2000 {
          .throttle_cap = "medium"
        } else if len < 5000 {
          .throttle_cap = "low"
        } else {
          .throttle_cap = "lowest"
        }
        # special case keys or caps for certain container types
        if .kubernetes.container_name == "opa" {
          if .message == "Bundle downloaded and activated successfully." {
            key.message = .message
            .throttle_cap = "lowest"
          } else if .message == "Received request." || .message == "Sent response." {
            key.message = .message
            key.req_path = .req_path
            if .req_path == "/health" || .req_path == "/metrics" {
              .throttle_cap = "lowest"
            } else {
              .throttle_cap = "high"
            }
          } else {
            .throttle_cap = "none"
          }
        } else if .kubernetes.container_name == "nginx" {
          .throttle_cap = "none"
        } else if .kubernetes.container_name == "manager" {
          key.message = .message
        } else if .kubernetes.container_name == "pulsarfunction" {
          key.namespace = .kubernetes.namespace_name
        }
        .throttle_key = encode_key_value(compact(key))
        {{- else }}
        .throttle_cap = "none"
        {{- end }}

    throttle_route:
      type: route
      inputs:
        - throttle_key
      route:
        high: .throttle_cap == "high"
        medium: .throttle_cap == "medium"
        low: .throttle_cap == "low"
        lowest: .throttle_cap == "lowest"

    throttle_high:
      type: throttle
      inputs:
        - throttle_route.high
      key_field: |-
        {{ print "{{ throttle_key }}" }}
      threshold: 100
      window_secs: 1

    throttle_medium:
      type: throttle
      inputs:
        - throttle_route.medium
      key_field: |-
        {{ print "{{ throttle_key }}" }}
      threshold: 50
      window_secs: 1

    throttle_low:
      type: throttle
      inputs:
        - throttle_route.low
      key_field: |-
        {{ print "{{ throttle_key }}" }}
      threshold: 10
      window_secs: 1

    throttle_lowest:
      type: throttle
      inputs:
        - throttle_route.lowest
      key_field: |-
        {{ print "{{ throttle_key }}" }}
      threshold: 1
      window_secs: 1

    # remove unused fields
    cleanup_fields:
      type: remap
      inputs:
        - throttle_high
        - throttle_medium
        - throttle_low
        - throttle_lowest
        - throttle_route._unmatched
      source: |-
        # keep fields in dev for debugging; remove elsewhere to save space
        {{- if ne .Values.shortEnv "dev" }}
        del(.throttle_key)
        del(.raw_message)
        del(.fluent_ts)
        del(.fluent_tag)
        del(.container_ts)
        del(.kubernetes)
        {{- end }}
        # splunk appends {} to the name of multivalued fields and treats them separately
        # from single valued fields of the same name, so this makes message consistently
        # multivalued so you can put just message{} in your table
        if is_string(.message) {
          .message = split(.message, "\n") ?? [.message]
        }
        . = compact(.)

# extraVolumes -- Additional Volumes to use with Vector Pods.
extraVolumes: []

# extraVolumeMounts -- Additional Volume to mount into Vector Containers.
extraVolumeMounts: []

# initContainers -- Init Containers to be added to the Vector Pods.
initContainers: []

# extraContainers -- Extra Containers to be added to the Vector Pods.
extraContainers: []

# Configuration for Vector's data persistence.
persistence:
  # persistence.enabled -- If true, create and use PersistentVolumeClaims.
  enabled: false
  # persistence.existingClaim -- Name of an existing PersistentVolumeClaim to use. Valid for the "Aggregator" role.
  existingClaim: ""
  # persistence.storageClassName -- Specifies the storageClassName for PersistentVolumeClaims. Valid for the
  # "Aggregator" role.
  # storageClassName: default

  # persistence.accessModes -- Specifies the accessModes for PersistentVolumeClaims. Valid for the "Aggregator" role.
  accessModes:
    - ReadWriteOnce
  # persistence.size -- Specifies the size of PersistentVolumeClaims. Valid for the "Aggregator" role.
  size: 10Gi
  # persistence.finalizers -- Specifies the finalizers of PersistentVolumeClaims. Valid for the "Aggregator" role.
  finalizers:
    - kubernetes.io/pvc-protection
  # persistence.selectors -- Specifies the selectors for PersistentVolumeClaims. Valid for the "Aggregator" role.
  selectors: {}

  hostPath:
    # persistence.hostPath.path -- Override path used for hostPath persistence. Valid for the "Agent" role, persistence
    # is always used for the "Agent" role.
    path: "/var/lib/vector"

# dnsPolicy -- Specify the [dnsPolicy](https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-s-dns-policy)
# for Vector Pods.
dnsPolicy: ClusterFirst

# dnsConfig -- Specify the [dnsConfig](https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-dns-config)
# options for Vector Pods.
dnsConfig: {}
  # nameservers:
  #   - 1.2.3.4
  # searches:
  #   - ns1.svc.cluster-domain.example
  #   - my.dns.search.suffix
  # options:
  #   - name: ndots
  #     value: "2"
  #   - name: edns0

# livenessProbe -- Override default liveness probe settings. If customConfig is used, requires customConfig.api.enabled
# to be set to true.
livenessProbe: {}
  # httpGet:
  #   path: /health
  #   port: api

# readinessProbe -- Override default readiness probe settings. If customConfig is used,
# requires customConfig.api.enabled to be set to true.
readinessProbe: {}
  # httpGet:
  #   path: /health
  #   port: api

# Configure a PodMonitor for Vector, requires the PodMonitor CRD to be installed.
podMonitor:
  # podMonitor.enabled -- If true, create a PodMonitor for Vector.
  enabled: false
  # podMonitor.jobLabel -- Override the label to retrieve the job name from.
  jobLabel: app.kubernetes.io/name
  # podMonitor.port -- Override the port to scrape.
  port: prom-exporter
  # podMonitor.path -- Override the path to scrape.
  path: /metrics
  # podMonitor.relabelings -- [RelabelConfigs](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config)
  # to apply to samples before scraping.
  relabelings: []
  # podMonitor.metricRelabelings -- [MetricRelabelConfigs](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#metric_relabel_configs)
  # to apply to samples before ingestion.
  metricRelabelings: []
  # podMonitor.additionalLabels -- Adds additional labels to the PodMonitor.
  additionalLabels: {}
  # podMonitor.honorLabels -- If true, honor_labels is set to true in the [scrape config](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config).
  honorLabels: false
  # podMonitor.honorTimestamps -- If true, honor_timestamps is set to true in the [scrape config](https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config).
  honorTimestamps: true

# Optional built-in HAProxy load balancer.
haproxy:
  # haproxy.enabled -- If true, create a HAProxy load balancer.
  enabled: false

  # Define the HAProxy image to use.
  image:
    # haproxy.image.repository -- Override default registry and name for HAProxy.
    repository: haproxytech/haproxy-alpine
    # haproxy.image.pullPolicy -- HAProxy image pullPolicy.
    pullPolicy: IfNotPresent
    # haproxy.image.pullSecrets -- The [imagePullSecrets](https://kubernetes.io/docs/concepts/containers/images/#specifying-imagepullsecrets-on-a-pod)
    # to reference for the HAProxy Pods.
    pullSecrets: []
    # haproxy.image.tag -- The tag to use for HAProxy's image.
    tag: "2.4.17"

  # haproxy.rollWorkload -- Add a checksum of the generated ConfigMap to the HAProxy Deployment.
  rollWorkload: true

  # haproxy.replicas -- Set the number of HAProxy Pods to create.
  replicas: 1

  serviceAccount:
    # haproxy.serviceAccount.create -- If true, create a HAProxy ServiceAccount.
    create: true
    # haproxy.serviceAccount.annotations -- Annotations to add to the HAProxy ServiceAccount.
    annotations: {}
    # haproxy.serviceAccount.name -- The name of the HAProxy ServiceAccount to use. If not set and create is true, a
    # name is generated using the fullname template.
    name:
    # haproxy.serviceAccount.automountToken -- Automount API credentials for the HAProxy ServiceAccount.
    automountToken: true

  # haproxy.strategy -- Customize the [strategy](https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/deployment-v1/)
  # used to replace HAProxy Pods.
  strategy: {}
    # rollingUpdate:
    #   maxSurge: 25%
    #   maxUnavailable: 25%
    # type: RollingUpdate

  # haproxy.terminationGracePeriodSeconds -- Override HAProxy's terminationGracePeriodSeconds.
  terminationGracePeriodSeconds: 60

  # haproxy.podAnnotations -- Set annotations on HAProxy Pods.
  podAnnotations: {}

  # haproxy.podLabels -- Set labels on HAProxy Pods.
  podLabels: {}

  # haproxy.podPriorityClassName -- Set the priorityClassName on HAProxy Pods.
  podPriorityClassName: ""

  # haproxy.podSecurityContext -- Allows you to overwrite the default PodSecurityContext for HAProxy.
  podSecurityContext: {}
    # fsGroup: 2000

  # haproxy.securityContext -- Specify securityContext on HAProxy containers.
  securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000

  # haproxy.containerPorts -- Manually define HAProxy's containerPorts, overrides automated generation of containerPorts.
  containerPorts: []

  # HAProxy's Service configuration.
  service:
    # haproxy.service.type -- Set type of HAProxy's Service.
    type: ClusterIP
    # haproxy.service.annotations -- Set annotations on HAProxy's Service.
    annotations: {}
    # haproxy.service.topologyKeys -- Specify the [topologyKeys](https://kubernetes.io/docs/concepts/services-networking/service-topology/#using-service-topology)
    # field on HAProxy's Service spec.
    topologyKeys: []
    #   - "kubernetes.io/hostname"
    #   - "topology.kubernetes.io/zone"
    #   - "topology.kubernetes.io/region"
    #   - "*"
    # haproxy.service.ports -- Manually set HAPRoxy's Service ports, overrides automated generation of Service ports.
    ports: []
    # haproxy.service.externalTrafficPolicy -- Specify the [externalTrafficPolicy](https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip).
    externalTrafficPolicy: ""
    # haproxy.service.loadBalancerIP -- Specify the [loadBalancerIP](https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer).
    loadBalancerIP: ""
    # haproxy.service.ipFamilyPolicy -- Configure [IPv4/IPv6 dual-stack](https://kubernetes.io/docs/concepts/services-networking/dual-stack/).
    ipFamilyPolicy: ""
    # haproxy.service.ipFamilies -- Configure [IPv4/IPv6 dual-stack](https://kubernetes.io/docs/concepts/services-networking/dual-stack/).
    ipFamilies: []

  # haproxy.existingConfigMap -- Use this existing ConfigMap for HAProxy's configuration instead of creating a new one.
  # Additionally, haproxy.containerPorts and haproxy.service.ports should be specified based on your supplied
  # configuration. If set, this parameter takes precedence over customConfig and the chart's default configs.
  existingConfigMap: ""

  # haproxy.customConfig -- Override HAProxy's default configs, if used **all** options need to be specified.
  # This parameter supports using Helm templates to insert values dynamically. By default, this chart will parse
  # Vector's configuration from customConfig to generate HAProxy's config, which can be overwritten with
  # haproxy.customConfig.
  customConfig: ""

  # haproxy.extraVolumes -- Additional Volumes to use with HAProxy Pods.
  extraVolumes: []

  # haproxy.extraVolumeMounts -- Additional Volume to mount into HAProxy Containers.
  extraVolumeMounts: []

  # haproxy.initContainers -- Init Containers to be added to the HAProxy Pods.
  initContainers: []

  # haproxy.extraContainers -- Extra Containers to be added to the HAProxy Pods.
  extraContainers: []

  autoscaling:
    # haproxy.autoscaling.enabled -- Create a HorizontalPodAutoscaler for HAProxy.
    enabled: false
    # haproxy.autoscaling.minReplicas -- Minimum replicas for HAProxy's HPA.
    minReplicas: 1
    # haproxy.autoscaling.maxReplicas -- Maximum replicas for HAProxy's HPA.
    maxReplicas: 10
    # haproxy.autoscaling.targetCPUUtilizationPercentage -- Target CPU utilization for HAProxy's HPA.
    targetCPUUtilizationPercentage: 80
    # haproxy.autoscaling.targetMemoryUtilizationPercentage -- (int) Target memory utilization for HAProxy's HPA.
    targetMemoryUtilizationPercentage:
    # haproxy.autoscaling.customMetric -- Target a custom metric for autoscaling.
    customMetric: {}
      #  - type: Pods
      #    pods:
      #      metric:
      #        name: utilization
      #      target:
      #        type: AverageValue
      #        averageValue: 95

  # haproxy.resources -- Set HAProxy resource requests and limits.
  resources: {}
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  # haproxy.livenessProbe -- Override default HAProxy liveness probe settings.
  livenessProbe:
    tcpSocket:
      port: 1024

  # haproxy.readinessProbe -- Override default HAProxy readiness probe settings.
  readinessProbe:
    tcpSocket:
      port: 1024

  # haproxy.nodeSelector -- Configure a [nodeSelector](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector)
  # for HAProxy Pods
  nodeSelector: {}

  # haproxy.tolerations -- Configure HAProxy Pods to be scheduled on [tainted](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/)
  # nodes.
  tolerations: []

  # haproxy.affinity -- Configure [affinity](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity)
  # rules for HAProxy Pods.
  affinity: {}

  # Custom datastax configs
  shortEnv: ""
  clusterID: ""
  throttleEnabled: true
